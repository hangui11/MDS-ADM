{"cells":[{"cell_type":"markdown","id":"6fc4328e","metadata":{"id":"6fc4328e"},"source":["# GRADIENT FLOW VISUALIZATION"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","dir = 'drive/MyDrive/MDS/ADM/'\n","import sys\n","sys.path.insert(1,dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ANRs3VJVkVQ","executionInfo":{"status":"ok","timestamp":1750104486693,"user_tz":-120,"elapsed":68746,"user":{"displayName":"Hang Yao","userId":"16080021779884015793"}},"outputId":"14c0ffbb-0cac-4254-aedf-a8d6a457b48e"},"id":"0ANRs3VJVkVQ","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","id":"1f053d0b","metadata":{"id":"1f053d0b"},"source":["Import the libraries and generate synthetic data."]},{"cell_type":"code","execution_count":3,"id":"3595e609","metadata":{"id":"3595e609","executionInfo":{"status":"ok","timestamp":1750104493364,"user_tz":-120,"elapsed":6674,"user":{"displayName":"Hang Yao","userId":"16080021779884015793"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","import matplotlib.colors as mcolors\n","import matplotlib.cm as cm\n","from matplotlib.animation import FuncAnimation\n","\n","np.random.seed(42)\n","\n","# 1) Prepare XOR dataset\\ nx = None\n","x1 = np.random.rand(1000, 1) * 10 - 5\n","x2 = np.random.rand(1000, 1) * 10 - 5\n","y_xor = np.logical_xor(x1 > 0, x2 > 0).astype(np.float32)\n","X = np.hstack([x1, x2]).astype(np.float32)\n","\n","dataset = tf.data.Dataset.from_tensor_slices((X, y_xor))\n","dataset = dataset.shuffle(buffer_size=100).batch(4)"]},{"cell_type":"markdown","id":"16c57231","metadata":{"id":"16c57231"},"source":["Define model in Keras"]},{"cell_type":"code","execution_count":4,"id":"d3d64754","metadata":{"id":"d3d64754","executionInfo":{"status":"ok","timestamp":1750104493383,"user_tz":-120,"elapsed":16,"user":{"displayName":"Hang Yao","userId":"16080021779884015793"}}},"outputs":[],"source":["def create_model():\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Dense(2, activation='relu', input_shape=(2,), name='hidden_layer'),\n","        tf.keras.layers.Dense(1, activation='sigmoid', name='output_layer')\n","    ])\n","    return model\n"]},{"cell_type":"markdown","id":"4bc4d8fd","metadata":{"id":"4bc4d8fd"},"source":[" Fixed graph layout"]},{"cell_type":"code","execution_count":5,"id":"11a23f80","metadata":{"id":"11a23f80","executionInfo":{"status":"ok","timestamp":1750104493402,"user_tz":-120,"elapsed":9,"user":{"displayName":"Hang Yao","userId":"16080021779884015793"}}},"outputs":[],"source":["data_ids = ['i0', 'i1']\n","hidden_ids = ['h0', 'h1']\n","output_ids = ['o0']\n","all_nodes = data_ids + hidden_ids + output_ids\n","layer_counts = [len(data_ids), len(hidden_ids), len(output_ids)]\n","max_nodes = max(layer_counts)\n","\n","def vertical_pos(layer, nodes):\n","    offset = (max_nodes - len(nodes)) / 2\n","    return {node: (layer, -(i + offset)) for i, node in enumerate(nodes)}\n","pos = {}\n","pos.update(vertical_pos(0, data_ids))\n","pos.update(vertical_pos(1, hidden_ids))\n","pos.update(vertical_pos(2, output_ids))"]},{"cell_type":"code","execution_count":6,"id":"dd10ce58","metadata":{"id":"dd10ce58","executionInfo":{"status":"ok","timestamp":1750104493460,"user_tz":-120,"elapsed":56,"user":{"displayName":"Hang Yao","userId":"16080021779884015793"}}},"outputs":[],"source":["def animate_gradient_flow(lr=0.01,\n","                           loss_threshold=1e-3,\n","                           max_epochs=100,\n","                           interval_ms=200,\n","                           save_path=\"xor.mp4\"):\n","    model = create_model()\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","    loss_fn = tf.keras.losses.BinaryCrossentropy()\n","\n","    # Records\n","    grad_norm_h = []  # for hidden layer weights\n","    grad_norm_o = []  # for output layer weights\n","    last_loss = 1e9\n","\n","    fig, (ax_graph, ax_grad) = plt.subplots(1, 2, figsize=(14, 6))\n","\n","    def update(epoch):\n","        nonlocal last_loss\n","        for x_batch, y_batch in dataset:\n","            with tf.GradientTape() as tape:\n","                preds = model(x_batch, training=True)\n","                loss = loss_fn(y_batch, preds)\n","            grads = tape.gradient(loss, model.trainable_weights)\n","            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","        last_loss = loss.numpy()\n","        g_h = tf.norm(grads[0]).numpy()\n","        g_o = tf.norm(grads[2]).numpy()\n","        grad_norm_h.append(g_h)\n","        grad_norm_o.append(g_o)\n","\n","        # Build network graph\n","        G = nx.DiGraph()\n","        for n in all_nodes:\n","            G.add_node(n)\n","        grad_h = np.abs(grads[0].numpy())\n","        grad_o = np.abs(grads[2].numpy())\n","        for i in range(2):\n","            for j in range(2):\n","                G.add_edge(data_ids[i], hidden_ids[j], weight=grad_h[i, j])\n","        for i in range(2):\n","            G.add_edge(hidden_ids[i], output_ids[0], weight=grad_o[i, 0])\n","\n","        weights = [G[u][v]['weight'] for u, v in G.edges()]\n","        vmax = max(weights) if weights else 1e-6\n","        norm = mcolors.Normalize(vmin=0, vmax=vmax)\n","        cmap = cm.get_cmap('plasma')\n","        colors = [cmap(norm(w)) for w in weights]\n","\n","        ax_graph.clear()\n","        nx.draw(G, pos, ax=ax_graph,\n","                with_labels=True, node_color='skyblue', node_size=800,\n","                arrows=True, edge_color=colors, width=2)\n","        labels = {(u, v): f\"{G[u][v]['weight']:.4f}\" for u, v in G.edges()}\n","        for (u, v), lbl in labels.items():\n","            x1, y1 = pos[u]; x2, y2 = pos[v]\n","            mx, my = (x1 + x2)/2, (y1 + y2)/2\n","            dx, dy = x2-x1, y2-y1\n","            length = np.hypot(dx, dy)\n","            px, py = -dy/length, dx/length\n","            offset = 0.2 if (u, v) in [(data_ids[0], hidden_ids[1]), (data_ids[1], hidden_ids[0])] else 0\n","            ax_graph.text(mx+px*offset, my+py*offset, lbl,\n","                          fontsize=8, ha='center', va='center',\n","                          bbox=dict(facecolor='white', pad=0.2))\n","        ax_graph.set_title(f\"Epoch {epoch+1} (loss={last_loss:.4f})\")\n","        ax_graph.axis('off')\n","\n","        ax_grad.clear()\n","        ax_grad.plot(range(1, len(grad_norm_h)+1), grad_norm_h, label='hidden grad norm')\n","        ax_grad.plot(range(1, len(grad_norm_o)+1), grad_norm_o, label='output grad norm')\n","        ax_grad.set_yscale('log')\n","        ax_grad.set_xlabel('Epoch')\n","        ax_grad.set_ylabel('Gradient Norm (log-scale)')\n","        ax_grad.set_title('Gradient Flow Over Epochs')\n","        ax_grad.legend(); ax_grad.grid(True)\n","\n","    def frame_generator():\n","        for epoch in range(max_epochs):\n","            yield epoch\n","            if last_loss < loss_threshold:\n","                print(f\"Converged at epoch {epoch+1} (loss={last_loss:.4f})\")\n","                break\n","\n","    anim = FuncAnimation(fig, update, frames=frame_generator(), interval=interval_ms, repeat=False)\n","    anim.save(save_path, writer='ffmpeg', dpi=150)\n","    plt.close(fig)\n","    print(f\"Saved TensorFlow gradient-flow animation to '{save_path}'\")"]},{"cell_type":"code","execution_count":7,"id":"486a2e97","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"486a2e97","executionInfo":{"status":"ok","timestamp":1750105351007,"user_tz":-120,"elapsed":857546,"user":{"displayName":"Hang Yao","userId":"16080021779884015793"}},"outputId":"cb95d127-4f42-450b-9ff3-96af855833a8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","<ipython-input-6-1453850257>:83: UserWarning: frames=<generator object animate_gradient_flow.<locals>.frame_generator at 0x7eb22042d690> which we can infer the length of, did not pass an explicit *save_count* and passed cache_frame_data=True.  To avoid a possibly unbounded cache, frame data caching has been disabled. To suppress this warning either pass `cache_frame_data=False` or `save_count=MAX_FRAMES`.\n","  anim = FuncAnimation(fig, update, frames=frame_generator(), interval=interval_ms, repeat=False)\n","<ipython-input-6-1453850257>:46: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  cmap = cm.get_cmap('plasma')\n"]},{"output_type":"stream","name":"stdout","text":["Saved TensorFlow gradient-flow animation to 'drive/MyDrive/MDS/ADM/xor.mp4'\n"]}],"source":["if __name__ == '__main__':\n","    animate_gradient_flow(save_path=dir+'xor.mp4')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}